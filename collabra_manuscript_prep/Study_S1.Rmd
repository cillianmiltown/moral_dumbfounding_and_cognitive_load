---
title             : "Study S1"
shorttitle        : "Cognitive Load and Moral Dumbfounding"
author:
  - name          : "Blinded"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Blinded"
    email         : "Blinded"
  - name          : "Blinded"
    affiliation   : "2"
  - name          : "Blinded"
    affiliation   : "1"
  - name          : "Blinded"
    affiliation   : "1"
affiliation:
  - id            : "1"
    institution   : "Blinded"
  - id            : "2"
    institution   : "Blinded"
author_note: |
  All procedures performed in studies involving human participants were approved by institutional research ethics committee and conducted in accordance with the Code of Professional Ethics of the Psychological Society of Ireland, and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards. Informed consent was obtained from all individual participants included in the study. The authors declare that there are no potential conflicts of interest with respect to the research, authorship, and/or publication of this article. All authors consented to the submission of this manuscript.
abstract: |
  Six studies etc.
keywords          : "keywords"
wordcount         : "TBC"
bibliography: "../resources/bib/My Library.bib"
csl: "../resources/bib/apa6.csl"
figsintext        : true
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
toc               : false
lang              : "en-US"
documentclass     : "apa7"
output:
  papaja::apa6_pdf
header-includes:
- \raggedbottom
editor_options: 
  chunk_output_type: console
---


```{r S1setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
# knitr::opts_chunk$set(eval = TRUE, echo = TRUE)
#knitr::opts_chunk$set(include = FALSE)
```


```{r S1load_libraries_cogload}
rm(list = ls())
library(citr)
#install.packages("sjstats")
library(plyr)
library(foreign)
library(car)
library(desnum)
library(ggplot2)
library(extrafont)
#devtools::install_github("crsh/papaja")
library(papaja)
#library("dplyr")
library("afex")
library("tibble")
library(scales)
#install.packages("metap")
library(metap)
library(pwr)
library(lsr)
#install.packages("sjstats")
library(sjstats)
library(DescTools)
#inatall.packages("ggstatsplot")
#library(ggstatsplot)
library(VGAM)
library(nnet)
library(mlogit)
library(reshape2)
#install.packages("powerMediation")
library("powerMediation")


# library(rstatix)


#source("load_all_data.R")

#devtools::install_github("benmarwick/wordcountaddin")
#library(wordcountaddin)
#wordcountaddin::text_stats("cogload_1to5_25Sept19.Rmd")
getwd()
```


# Study S1: Number-Letter Task (College Sample)
The aim of Study S1 was to investigate if a cognitive load manipulation influenced participants' ability to justify their judgement. We also measured Need for Cognition [@cacioppo_need_1982; Petty et al., -@petty_efficient_1984] as a potential moderator variable.

```{r S1load data set Study S1}

rm(list = ls())

load("../loaded_data/one.RData")
df3 <- study_1

df4 <- df3[which(df3$condition=="cog_load"),]
df5 <- df3[which(df3$condition=="control"),]


```

## Study S1: Method
### Study S1: Participants and design
Study S1 was a between subjects design.  The dependent variable was rates of providing reasons/dumbfounding (measured using to the critical slide with 3 response options: 1: providing reasons; 2: there is nothing wrong; 3: dumbfounded response - admission).  The independent variable was cognitive load with two levels: present and absent.  Cognitive load was manipulated by presenting participants with an eight digit number letter string to be memorized.  Need for Cognition [@cacioppo_need_1982; Petty et al., -@petty_efficient_1984] was included as an additional potential predictor variable. 

A total sample of `r length(df3$InCS)` participants (`r sum(df3$gender=="Female")` female, `r sum(df3$gender=="Male")` male; *M*~age~ = `r round(mean(df3$age),digits=2)`, min = `r min(df3$age)`, max = `r max(df3$age)`, *SD* = `r round(sd(df3$age),digits=2)`) took part.  Participants in this sample were undergraduate students, postgraduate students, and alumni from Mary Immaculate College (MIC), and University of Limerick (UL).  Participation was voluntary and participants were not reimbursed for their participation.

### Study S1: Procedure and materials
Data were collected using an online questionnaire. Data collection took place in a designated computer laboratory in MIC.  The experimenter remained in the laboratory for the duration of the study. Participants were first presented with an information sheet and consent form.  The main study proceeded when participants had signed the consent form.

Participants in the experimental condition were presented with an eight digit number/letter string and asked to memorise the sequence.  After 30 seconds, the experiment progressed to the next slide. Participants had the option to click "ok" and progress to the next slide after 15 seconds.

Participants were then presented with the "Julie and Mark" (*Incest*) vignette [@haidt_moral_2000].  Participants rated on a 7-point Likert scale how right or wrong the behaviour of Julie and Mark was (where, 1 = *Morally wrong*; 4 = *neutral*; 7 = *Morally right*), and were given an opportunity to provide reasons for their judgement. Following this, participants were presented with a series of counter-arguments, which refuted commonly used justifications for rating the behaviour as "wrong".

Dumbfounding was measured using the critical slide [McHugh et al., -@mchugh_searching_2017a].  This contained a statement defending the behaviour and a question as to how the behaviour could be wrong ("Julie and Mark's behaviour did not harm anyone, how can there be anything wrong with what they did?").  There were three possible answer options: (a) "There is nothing wrong"; (b) an admission of not having reasons ("It's wrong but I can't think of a reason"); and finally a judgement with accompanying justification (c) "It's wrong and I can provide a valid reason".  The order of these response options was randomised. Participants who selected (c) were prompted to type a reason.  The selecting of option (b), the admission of not having reasons, was taken to be a dumbfounded response. We note that this measure provides a conservative measure of dumbfounded responding [see McHugh et al., -@mchugh_searching_2017a for discussion].

Following the critical slide, participants in the experimental condition were required to reproduce the eight digit number-letter string sequence presented previously.  Following this a post-discussion questionnaire in which participants rated their response to the scenario across various dimensions [@haidt_moral_2000].

Need for Cognition was measured using the short form of the Need for Cognition scale [@cacioppo_need_1982; Petty et al., -@petty_efficient_1984].  This is an 18 item scale containing questions relating to motivation to engage in thinking (e.g., "I would prefer complex to simple problems"). Responses were recorded on a -4 to +4 Likert-type scale, where -4 = *very strong disagreement* and +4 = *very strong agreement*.

## Study S1: Results



```{r S1s1change in judgement}

# create variables for reporting t.tests
t <- t.test(df3$InJu1,df3$InJu2, paired = TRUE)

#chisquare test function

custom_chi <- function(x,y){
  a <- length(x)
  b <- length(y)
  c <- rep(1, a)
  d <- rep(2, b)
  e <- c(c,d)
  f <- c(x, y)
  
  g <- data.frame(e,f)
  h <- table(g$e,g$f)
  suppressWarnings(chisq.test(h))
}

c <- suppressWarnings(custom_chi(df3$InJu1,df3$InJu2))

changed_num <- function(x, judgement_1, judgement_2){
  b <- b <- x[which(x$Ju1_bin==judgement_1 & x$Ju2_bin==judgement_2),]
  length(b$Ju1_bin)
  
}

tot_changed_num <- function(x, query){
  
  c <- cbind.data.frame(x$Ju1_bin[which(x$Ju1_bin!=x$Ju2_bin)],x$Ju2_bin[which(x$Ju1_bin!=x$Ju2_bin)])
  colnames(c) <- c("initial_judgement","revised_judgement")
  
  c
  if(query == "table") print(c)
  if(query == "total") print(length(c$initial_judgement))}


tot_changed_table <- function(x){
  
  c <- cbind.data.frame(x$Ju1_bin[which(x$Ju1_bin!=x$Ju2_bin)],x$Ju2_bin[which(x$Ju1_bin!=x$Ju2_bin)])
  colnames(c) <- c("Initial Judgment","Revised Judgment")
  
  c
  }

change_table <- tot_changed_table(college)

```


```{r S1checkingchanges1}

t_j1 <- t.test(college$InJu1 ~ college$condition)
d_j1 <- cohensD(college$InJu1 ~ college$condition)

t_paragraph(college$InJu1, college$condition, "initial judgement")
#t_paragraph(one$InJu1, one$condition, "initial judgement")
#t_paragraph(two$InJu1, two$condition, "initial judgement")
#t_paragraph(three$InJu1, three$condition, "initial judgement")


t_j2 <- t.test(college$InJu2 ~ college$condition)
d_j2 <- cohensD(college$InJu2 ~ college$condition)

t_paragraph(college$InJu2, college$condition, "revised judgement")
#t_paragraph(one$InJu1, one$condition, "initial judgement")
#t_paragraph(two$InJu1, two$condition, "initial judgement")
#t_paragraph(three$InJu1, three$condition, "initial judgement")

t_paired_paragraph(college$InJu1,college$InJu2, "judgment")
t_j3 <- t.test(college$InJu1,college$InJu2,paired = TRUE)
d_j3 <- cohensD(college$InJu1,college$InJu2, method = "paired")


```


```{r S1prepS1fig2}


y <- table(df3$condition,df3$InCS)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")

z <- as.data.frame(table(df3$condition,df3$InCS)/length(df3$gender)*2)
perc <- z$Freq
test <- cbind(y,perc)
test$condition
test


y <- table(df3$condition,df3$Dumb_incl_string)
y <- as.data.frame(y)
colnames(y) <- c("condition","InCS","Freq")




ab_graph <- function(){
  a <- df3[which(df3$condition==levels(as.factor(df3$condition))[1]),]
  b <- df3[which(df3$condition==levels(as.factor(df3$condition))[2]),]
  #levels(as.factor(df3$condition))[1]
  
  ay <- as.data.frame(table(a$InCS,a$condition))
  by <- as.data.frame(table(b$InCS,b$condition))
  
  aperc <- ay$Freq/length(a$gender)
  ay <- cbind(ay,aperc)
  colnames(ay) <- c("InCS","condition","Freq","perc")
  
  bperc <- by$Freq/length(b$gender)
  by <- cbind(by,bperc)
  colnames(by) <- c("InCS","condition","Freq","perc")
  
  c <- rbind(ay,by)
  
  c
}

test <- ab_graph()

rm(y)
```



```{r}

x <- df3

se_fun <- function(a,b){
  k <- length(a$gender)
  n <- length(b$gender)
  
  pbar <- k/n
  a$pbar <- pbar
  a$se = sqrt(pbar * (1 - pbar)/n)
  a}
# https://www.r-tutor.com/elementary-statistics/interval-estimation/interval-estimate-population-proportion

y <- rbind(
  se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong and I can provide a valid reason."),]
         ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="control"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="control"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong and I can provide a valid reason."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="There is nothing wrong."),]
          ,x[which(x$condition=="cog_load"),])
  ,se_fun(x[which(x$condition=="cog_load"&x$InCS=="It's wrong but I can't think of a reason."),]
          ,x[which(x$condition=="cog_load"),])
)

y1 <- y %>% select("InCS","condition","pbar","se")


test1 <- dplyr::left_join(test,y1, by = c("condition","InCS") )

```

```{r}

g <- ggplot(test1, aes(x=reorder(InCS), y=perc, fill=factor(condition,labels=c("Cognitive load","Control")))) +
  scale_y_continuous(limits = c(-.03,1),
                     labels = percent_format()
  )+ 
  geom_col(position = "dodge",
           color="black",
           size=.2
  )+
  geom_errorbar(aes(ymin=perc-se, ymax=perc+se), size=.2, width=.2,
               position=position_dodge(.9), color=#"black" #
                 "#5a5a5a"
                 )+
  geom_text(#family = "Times",
            size=3,
            aes( label = scales::percent(perc, accuracy = 1),
                 y= perc ),
            stat= "identity",
            vjust = -.5,
            hjust = +1.1,
            position = position_dodge(.9),
            fontface='plain'
            )+
  geom_text(#family = "Times", 
            size=3.5,
            aes(label = format(Freq),
                y= -2.5*(..count../100)/(..count..)),
            stat= "count",
            position = position_dodge(0.9),
            #vjust = -.05,
            fontface='plain'
            ) +
  xlab("Response to Critical Slide") +
  ylab("Percentage of participants selecting each response")+
  scale_x_discrete(labels=c("Reasons", "Dumbfounded","Nothing Wrong")) +
  scale_fill_grey(start = .5, end = .8) +
  labs(fill="Condition") +
  #theme_apa() +
  theme_bw() +
  theme(panel.border = element_blank(),
        axis.line = element_line(size = .2),
        strip.background  = element_blank(),
        panel.grid = element_blank(),
        plot.title=element_text(#family="Times",
                                size=12
                                ),
        legend.text=element_text(#family="Times",
                                 size=8
                                 ),
        legend.title=element_text(#family="Times",
                                    size=10
                                 ),
        axis.text=element_text(#family="Times",
                                 colour = "black",
                                 size=8
                                 ),
        axis.ticks.x = element_blank(),
        axis.title=element_text(#family="Times",
                                  size=12
                                  ),
        strip.text=element_text(#family = "Times",
                                  size = 12
                                  ),
        #strip.background = element_rect(fill = "white"),
        legend.position="right")

```


```{r S1S1fig2criticalcondition, fig.cap="Study S1: Responses to critical slide and for the experimental group (N = 33) and the control group (N = 33); (error bars represent standard error of the proportion)", include=TRUE}

suppressWarnings(print(g))


```


```{r S1prepplottinglogit1}

df3 <- df3[which(is.na(df3$NFC)==FALSE),]

x <- df3$NFC
y <- as.numeric(df3$InCS)

m1 <- multinom(y ~ x)
# summary(m1)
newdata <- data.frame(x = seq(min(x), max(x), length.out = 100))
p1 <- predict(m1, newdata, type = "class")
p2 <- predict(m1, newdata, type = "probs")


logit_plot <- cbind.data.frame(newdata,p2)

logit_plot <- `colnames<-`(logit_plot, c("x","one_l","two_l","three_l"))
logit_plot <- melt(logit_plot, id="x")

```


```{r S1ggplotlogit1, fig.cap="Study S1: Probability of selecting each response to the critical slide depending on Need for Cognition", include=TRUE}


ggplot(logit_plot,
       aes(x=x, y=value,
           #color=factor(variable,labels=c("dumb","reason","nothing"))
           linetype=factor(variable,labels=c("dumb","reason","nothing"))
           )) +
  geom_line()+
  xlab("Need for Cognition") + ylab("Predicted Probability") +
  scale_y_continuous(limits = c(0, 1)) + 
  #scale_color_discrete(name="Response to \nCritical Slide", labels=c("Dumbfounded","Nothing Wrong","Reasons"))+
  scale_linetype_discrete(name="Response to \nCritical Slide", labels=c("Dumbfounded","Nothing Wrong","Reasons"))+
  theme_bw() +
  theme(plot.title=element_text(#family="Times",
                                size=12
  ),
  legend.text=element_text(#family="Times",
                           size=8
  ),
  legend.title=element_text(#family="Times",
                            size=10
  ),
  axis.text=element_text(#family="Times",
                         colour = "black",
                         size=8
  ),
  axis.ticks.x = element_blank(),
  axis.title=element_text(#family="Times",
                          size=12
  ),
  strip.text=element_text(#family = "Times",
                          size = 12
  ),
  strip.background = element_rect(fill = "white"),
  legend.position="right")


```


\newpage


\newpage 


`r numbers2words_cap1(length(df3$Ju1_bin[df3$Ju1_bin=="wrong"]))` participants (`r round(((length(df3$Ju1_bin[df3$Ju1_bin=="wrong"])/length(df3$Ju1_bin))*100), digits=2)`%) rated the behavior of Julie and Mark as wrong initially, and `r numbers2words(length(df3$Ju2_bin[df3$Ju2_bin=="wrong"]))` participants (`r round(((length(df3$Ju2_bin[df3$Ju2_bin=="wrong"])/length(df3$Ju2_bin))*100), digits=2)`%) rated the behavior as wrong at the end of the task. Initial ratings (*M* = `r round(mean(df3$InJu1), digits = 2)`, *SD* = `r round(sd(df3$InJu1), digits = 2)`) were significantly more severe than revised ratings (*M* = `r round(mean(df3$InJu2), digits = 2)`, *SD* = `r round(sd(df3$InJu2), digits = 2)`), *t*(`r t_j3$parameter`) = `r t_j3$statistic`, *p* `r paste(p_report(t_j3$p.value))`; *d* = `r round(d_j3, digits=2)`. Inspection of the binned judgments revealed that `r numbers2words(tot_changed_num(college, "total"))` participants changed the valence of their judgments, and all but one of these involved included a "neutral" response for either the initial judgment or revised judgment Table\ \@ref(tab:tabS1change). 

```{r tabs1change in judgement}

# create variables for reporting t.tests
t <- t.test(df3$InJu1,df3$InJu2, paired = TRUE)

#chisquare test function

custom_chi <- function(x,y){
  a <- length(x)
  b <- length(y)
  c <- rep(1, a)
  d <- rep(2, b)
  e <- c(c,d)
  f <- c(x, y)
  
  g <- data.frame(e,f)
  h <- table(g$e,g$f)
  suppressWarnings(chisq.test(h))
}

c <- suppressWarnings(custom_chi(df3$InJu1,df3$InJu2))

changed_num <- function(x, judgement_1, judgement_2){
  b <- b <- x[which(x$Ju1_bin==judgement_1 & x$Ju2_bin==judgement_2),]
  length(b$Ju1_bin)
  
}

tot_changed_num <- function(x, query){
  
  c <- cbind.data.frame(x$Ju1_bin[which(x$Ju1_bin!=x$Ju2_bin)],x$Ju2_bin[which(x$Ju1_bin!=x$Ju2_bin)])
  colnames(c) <- c("Initial Judgment","Revised Judgment")
  
  c
  if(query == "table")
    print(c)
  if(query == "total") print(length(c$initial_judgement))}


tot_changed_table <- function(x){
  
  c <- cbind.data.frame(x$Ju1_bin[which(x$Ju1_bin!=x$Ju2_bin)],x$Ju2_bin[which(x$Ju1_bin!=x$Ju2_bin)])
  colnames(c) <- c("Initial Judgment","Revised Judgment")
  
  c
  }

change_table <- tot_changed_table(df3)
change_table <- table(change_table)
change_table <- as.data.frame(change_table)
change_table <- change_table[which(change_table$Freq!=0),]
change_table <- change_table[order(change_table$Initial.Judgment, change_table$Revised.Judgment), ]
colnames(change_table) <- c("Initial Judgment","Revised Judgment", "Total Changed")
#order(change_table$Initial.Judgment)
```



```{r tabS1change,results = 'asis', include=TRUE}


apa_table(
   change_table
   , align = c("c", "c")
   , caption = "Study S1 – Changes in Jugment"
   #, added_stub_head = "Response to critical slide"
   #, col_spanners = makespanners()
   #, note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


Participants who selected the admission of not having reasons on the critical slide were identified as dumbfounded.  `r numbers2words_cap1(length(df3$InCS[which(df3$InCS=="It's wrong but I can't think of a reason.")]))` participants (`r round((length(df3$InCS[which(df3$InCS=="It's wrong but I can't think of a reason.")])/(length(df3$InCS)))*100, digits=2)`%) selected "It's wrong but I can't think of a reason".  `r numbers2words_cap1(length(df3$InCS[which(df3$InCS=="It's wrong and I can provide a valid reason.")]))` participants (`r round((length(df3$InCS[which(df3$InCS=="It's wrong and I can provide a valid reason.")])/(length(df3$InCS)))*100,digits=2)`%) selected “It's wrong and I can provide a valid reason”; and `r numbers2words(length(df3$InCS[which(df3$InCS=="There is nothing wrong.")]))` participants (`r round((length(df3$InCS[which(df3$InCS=="There is nothing wrong.")])/(length(df3$InCS)))*100,digits=2)`%) selected “There is nothing wrong”.


```{r}

c <- chisq.test(table(df3$InCS,df3$condition))
w <- sqrt(c[]$statistic/length(df3$gender))
pw <- pwr.chisq.test(w=w,N=length(df3$InCS),df=(3-1),sig.level = .05)

```



```{r}

df3$InCS <- df3$InCS

test <- as.data.frame.matrix((table(df3$InCS,df3$condition)))
`rownames<-`(test, c("nothing wrong","no reason","reasons"))
test <- as.matrix((test))
test1 <- cbind(test[,1],test[,2])
test2 <- `colnames<-`(test1, c("cognitive load","control"))

tb_count_perc <- function(x){
  tc <- table(x$InCS,x$condition)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$condition=="cog_load")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$condition=="control")*100),"%"))
  }
  
tb_count_perc_eng <- function(x){
  tc <- table(x$InCS,x$engaged)
  cbind(tc[,1],paste0(round(tc[,1]/sum(x$engaged=="engaged")*100),"%"),
        tc[,2],paste0(round(tc[,2]/sum(x$engaged=="not engaged")*100),"%"))
  }
  
test <- tb_count_perc(df3)
test <- as.data.frame(test)
colnames(test) <- c("N","\\%","N","\\%")
  
makespanners <- function(){
  cog_load <- c(2,3)
  control <- c(4,5)
  spans <- list(cog_load,control)
  names(spans) <- c("Cognitive Load","Control")
  spans
}

#test <- tb_count_perc(df3)
#tb_count_perc(df3a)

df3 <- study_1


```


```{r tabS1tab1dumb1all,results = 'asis', include=TRUE}


apa_table(
   test
   , align = c("l", "c", "c", "c", "c")
   , caption = "Study S1 – Response to the critical slide depending on cognitive load"
   #, added_stub_head = "Response to critical slide"
   , col_spanners = makespanners()
   #, note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


```{r S1ch5cognitive load manipulationS1, include=FALSE}


df_a <- df3[which(df3$cog_right=="right"&df3$cog_M_ch_bin=="easy"),]
table(df_a$InCS)
numbers2words(sum(df_a$InCS=="There is nothing wrong."))
numbers2words(sum(df_a$InCS=="It's wrong but I can't think of a reason."))
numbers2words(sum(df_a$InCS=="It's wrong and I can provide a valid reason."))


df4 <- df3[which(df3$condition=="cog_load"),]
df5 <- df3[which(df3$condition=="control"),]
c <- chisq.test(table(df3$InCS,df3$condition))
#table(df3$InCS,df3$condition)

descriptives(df4$cog_number_right)
table(df4$cog_number_right)
table(df4$cog_M_ch_bin)
table(df4$cog_M_ch_bin,df4$cog_number_right)
numbers2words(min(df4$cog_number_right))

cbind(
  df4$cog_right,
  df4$cog_number_right
)
sum(df4$cog_number_right==0)

#c
```




Regarding the cognitive load manipulation, `r as_word(length(df3$cog_number_right[df3$cog_number_right==8]))` participants (`r round((length(df3$cog_number_right[df3$cog_number_right==8])/length(df3$condition[df3$condition=="cog_load"]))*100, digits=2)`%) successfully remembered the sequence of numbers and letters in full, and `r as_word(length(df3$cog_M_ch_bin[df3$cog_M_ch_bin=="easy"]))` participants (`r round((length(df3$cog_M_ch_bin[df3$cog_M_ch_bin=="easy"])/length(df3$condition[df3$condition=="cog_load"]))*100, digits=2)`%) indicated they found the memory task easy. Of these, `r as_word(length(df3$cog_number_right[df3$cog_number_right==8&df3$cog_M_ch_bin=="easy"]))` participants both found the task easy and got the answer right.  All participants correctly remembered at least two digits, indicating at least some level of engagement with the cognitive load manipulation. There were no differences in initial judgement, *t*(`r t_j1$parameter`) = `r t_j1$statistic`, *p* `r paste(p_report(t_j1$p.value))`; *d* = `r round(d_j1, digits=2)`, or revised judgment, *t*(`r t_j2$parameter`) = `r t_j2$statistic`, *p* `r paste(p_report(t_j2$p.value))`; *d* = `r round(d_j2, digits=2)`, depending on cognitive load.


```{r}

c <- chisq.test(table(df3$InCS,df3$condition))
w <- sqrt(c[]$statistic/length(df3$gender))
pw <- pwr.chisq.test(w=w,N=length(df3$InCS),df=(3-1),sig.level = .05)

```

To test our main hypotheses we conducted a chi-squared test for independence which revealed a significant association between experimental condition and response to the critical slide, $\chi$^2^(`r c$parameter`, *N* = `r length(df3$Ju1_bin)`) = `r round(c$statistic, digits=3)`, *p* `r paste(p_report(c$p.value))`, *V* = `r w`, the observed power was `r pw$power`.  Under cognitive load fewer participants (`r sum(df4$InCS=="It's wrong and I can provide a valid reason.")`; `r sum(df4$InCS=="It's wrong and I can provide a valid reason.")/length(df4$gender)*100`%) provided reasons than in the control condition (`r sum(df5$InCS=="It's wrong and I can provide a valid reason.")`; `r sum(df5$InCS=="It's wrong and I can provide a valid reason.")/length(df5$gender)*100`%).  Similarly, under cognitive load more participants (`r sum(df4$InCS=="There is nothing wrong.")`; `r sum(df4$InCS=="There is nothing wrong.")/length(df4$gender)*100`%) selected "There is nothing wrong" than in the control group (`r sum(df5$InCS=="There is nothing wrong.")`; `r sum(df5$InCS=="There is nothing wrong.")/length(df4$gender)*100`%).  The responses to the critical slide for the experimental group (*N* = `r sum(college$condition=="cog_load")`) and the control group (*N* = `r sum(college$condition=="control")`) are displayed in Figure\ \@ref(fig:S1S1fig2criticalcondition) and Table\ \@ref(tab:tabS1tab1dumb1all).  The observed counts, expected counts and standardised residuals are displayed in Table\ \@ref(tab:S1tab1dumb).  





```{r S1preptableS1}
c <- chisq.test(table(df3$InCS,df3$condition))
rownames(rbind(c$observed,c$expected,c$stdres))



ps <- function(y){
  if(as.numeric(sqrt( y*y) ) >3.3) print(paste0(y,"**"), quote = FALSE)
  else if(as.numeric(sqrt( y*y) ) >1.96) print(paste0(y,"*"), quote = FALSE)
  else print(y)}


x <- c$stdres
x <- round(x, digits = 2)

lapply(x, ps)

#c$stdres <- round(c$stdres,digits=3)
#c$stdres <- ps(c$stdres)

ps(x[1])
ps(x[2])
ps(x[3])

x <- `colnames<-`(
  cbind.data.frame(c(ps(x[1]),ps(x[2]),ps(x[3])),
                   c(ps(x[4]),ps(x[5]),ps(x[6]))),
  c("cog_load","control")
)

rownames(x) <- row.names(c$observed)  

y <- rbind(round(c$observed), round(c$expected, digits = 2))

c(c$stdres[1])


res <- cbind(c("Observed count","","","Expected count","","","Standardised residuals","",""),
      c("Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong",
        "Reasons","Dumbfounded","Nothing Wrong"),
      rbind(y,x)
      
      )

row.names(res) <- NULL
colnames(res) <- c("","","Cognitive Load","Control")




```

```{r S1tab1dumb,results = 'asis', include=TRUE}


apa_table(
   res
   , align = c("l", "l", "c", "c", "c")
   , caption = "Study S1 – Observed counts, expected counts, and standardised residuals for each response to the critical slide depending on cognitive load"
   #, added_stub_head = "Response to critical slide"
   #, col_spanners = makespanners()
   , note = "* = sig. at \\emph{p} < .05; ** = sig. at \\emph{p} < .001"
   , escape = FALSE
   
)

```


```{r S1logit1b}

#df3$InCS <- relevel(df3$InCS, ref = 2)

df3a <- mlogit.data(df3, choice = "InCS", shape = "wide")
InCSModel<-mlogit(InCS ~ 1 | condition+NFC, data = df3a, reflevel = "It's wrong and I can provide a valid reason."
                  )

summary_InCS_model <- summary(InCSModel)
summary_InCS_model$lratio$parameter
summary_InCS_model$lratio$statistic
summary_InCS_model$lratio$p.value

InCSModel$coefficients[3]
InCSModel$coefficients[4]

cox <- PseudoR2(multinom(InCS~condition+NFC,df3), "all")

cox[3]
cox[4]
#PseudoR2(x, "all")
#summary_InCS_model


wald1 <- 
  summary_InCS_model$CoefTable[3]^2 /
  summary_InCS_model$CoefTable[7]^2

wald2 <- 
  summary_InCS_model$CoefTable[4]^2 /
  summary_InCS_model$CoefTable[8]^2


summary_InCS_model
summary_InCS_model$coefficients[3]
data.frame(exp(InCSModel$coefficients))

exp(InCSModel$coefficients)[3]


a <- exp(confint(InCSModel))
c(a[3],a[7])

residuals(InCSModel)
fitted(InCSModel, outcome = F)

c <- summary_InCS_model$lratio$statistic
w <- sqrt(c/length(df3$gender))
pw <- pwr.chisq.test(w=w,N=length(df3$InCS),df=(2),sig.level = .05)

pw$power

revised_PseudoR2s <- function(LogModel) {
  dev <- LogModel$deviance
  nullDev <- LogModel$null.deviance
  modelN <- length(LogModel$fitted.values)
  R.l <- 1 - dev / nullDev
  R.cs <- 1- exp ( -(nullDev - dev) / modelN)
  R.n <- R.cs / ( 1 - ( exp (-(nullDev / modelN))))
  
  all <- list(hosmer_and_lemeshow = as.numeric(R.l), mcfadden = NA, cox_and_snell = as.numeric(R.cs), nagelkerke = as.numeric(R.n))
  all
}

logits_rsquared <- glm(InCS~NFC,df3, family = binomial(link = "logit"))
cox <- revised_PseudoR2s(logits_rsquared)

```

```{r S1logit1}

df3$InCS <- relevel(df3$InCS, ref = 2)

df3a <- mlogit.data(df3, choice = "InCS", shape = "wide")
InCSModel<-mlogit(InCS ~ 1 | NFC, data = df3a, reflevel = "It's wrong and I can provide a valid reason.")

summary_InCS_model <- summary(InCSModel)
summary_InCS_model$lratio$parameter
summary_InCS_model$lratio$statistic
summary_InCS_model$lratio$p.value

InCSModel$coefficients[3]
InCSModel$coefficients[4]

cox <- PseudoR2(multinom(InCS~NFC,df3), "all")

cox[3]
cox[4]
#PseudoR2(x, "all")
#summary_InCS_model


wald1 <- 
  summary_InCS_model$CoefTable[3]^2 /
  summary_InCS_model$CoefTable[7]^2

wald2 <- 
  summary_InCS_model$CoefTable[4]^2 /
  summary_InCS_model$CoefTable[8]^2


summary_InCS_model
summary_InCS_model$coefficients[3]
data.frame(exp(InCSModel$coefficients))

exp(InCSModel$coefficients)[3]


a <- exp(confint(InCSModel))
c(a[3],a[7])

residuals(InCSModel)
fitted(InCSModel, outcome = F)

c <- summary_InCS_model$lratio$statistic
w <- sqrt(c/length(df3$gender))
pw <- pwr.chisq.test(w=w,N=length(df3$InCS),df=(2),sig.level = .05)

pw$power

revised_PseudoR2s <- function(LogModel) {
  dev <- LogModel$deviance
  nullDev <- LogModel$null.deviance
  modelN <- length(LogModel$fitted.values)
  R.l <- 1 - dev / nullDev
  R.cs <- 1- exp ( -(nullDev - dev) / modelN)
  R.n <- R.cs / ( 1 - ( exp (-(nullDev / modelN))))
  
  all <- list(hosmer_and_lemeshow = as.numeric(R.l), mcfadden = NA, cox_and_snell = as.numeric(R.cs), nagelkerke = as.numeric(R.n))
  all
}

logits_rsquared <- glm(InCS~NFC,df3, family = binomial(link = "logit"))
cox <- revised_PseudoR2s(logits_rsquared)

```

```{r S1fullcombinedtestlogit, include=FALSE}
# taken from https://stats.idre.ucla.edu/r/dae/multinomial-logistic-regression/
#ml$prog2 <- relevel(ml$prog, ref = "academic")
df3 <- df3[which(is.na(df3$NFC)==FALSE),]
df3$InCS <- relevel(df3$InCS, ref = 3)

test <- multinom(InCS ~ condition + NFC, data = df3)
summary(test)
z <- summary(test)$coefficients/summary(test)$standard.errors
z
p <- (1 - pnorm(abs(z), 0, 1)) * 2
p

exp(coef(test))
head(pp <- fitted(test))

## different order from here, be careful

dses <- data.frame(condition = c("cog_load", "control" ), NFC = mean(df3$NFC))
predict(test, newdata = dses, "probs")

dwrite <- data.frame(condition = rep(c("cog_load", "control" ), each = 41), NFC = rep(c(30:70),
    2))

## store the predicted probabilities for each value of ses and write
pp.write <- cbind(dwrite, predict(test, newdata = dwrite, type = "probs", se = TRUE))

## calculate the mean probabilities within each level of ses
by(pp.write[, 3:5], pp.write$condition, colMeans)

lpp <- melt(pp.write, id.vars = c("condition", "NFC"), value.name = "probability")
head(lpp)

ggplot(lpp, aes(x = NFC, y = probability, colour = variable)) + geom_line() + facet_grid(. ~ condition, scales = "free")

```

A multinomial logistic regression revealed no significant association between Need for Cognition and response to the critical slide, $\chi$^2^(`r summary_InCS_model$lratio$parameter`, *N* = `r length(df3$gender)`) = `r round(summary_InCS_model$lratio$statistic, digits=2)`, *p* `r paste(p_report(summary_InCS_model$lratio$p.value))`, the observed power was `r round(pw$power,digits=2)`.



